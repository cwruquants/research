{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "    \n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    ")\n",
    "\n",
    "text1 = \"This is a good cup of coffee.\"\n",
    "text2 = \"This cup of coffee is good but not the best I've had.\"\n",
    "\n",
    "prediction = sentiment_analyzer(text1)[0]\n",
    "prediction2 = sentiment_analyzer(text2)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'positive', 'score': 0.9566965103149414}\n",
      "{'label': 'negative', 'score': 0.6155491471290588}\n"
     ]
    }
   ],
   "source": [
    "print(prediction)\n",
    "print(prediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in exposure:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input file: risk_contexts.csv\n",
      "Columns in the DataFrame: Index(['Table 1', 'context', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6'],\n",
      "      dtype='object')\n",
      "Performing sentiment analysis...\n",
      "Loading tokenizer and model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to risk_contexts_with_sentiment.csv\n",
      "\n",
      "Sentiment Distribution:\n",
      "neutral     2\n",
      "negative    2\n",
      "positive    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment Score Statistics:\n",
      "count    6.000000\n",
      "mean     0.102333\n",
      "std      0.585018\n",
      "min     -0.596000\n",
      "25%     -0.316750\n",
      "50%      0.059000\n",
      "75%      0.481250\n",
      "max      0.912000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "\n",
    "def perform_sentiment_analysis(df, text_column):\n",
    "    \"\"\"\n",
    "    Perform sentiment analysis on the given DataFrame using twitter-roberta-base-sentiment-latest\n",
    "    \"\"\"\n",
    "    # Load tokenizer and model\n",
    "    print(\"Loading tokenizer and model...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Initialize lists to store results\n",
    "    sentiment_labels = []\n",
    "    sentiment_scores = []\n",
    "    \n",
    "    # Process texts in batches\n",
    "    batch_size = 32\n",
    "    texts = df[text_column].tolist()\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize texts\n",
    "        encoded = tokenizer(batch_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "        \n",
    "        # Get model predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded)\n",
    "            scores = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "            scores = scores.cpu().numpy()\n",
    "        \n",
    "        # Process each prediction in the batch\n",
    "        for score in scores:\n",
    "            # Get label (0: negative, 1: neutral, 2: positive)\n",
    "            label_id = score.argmax()\n",
    "            label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "            label = label_map[label_id]\n",
    "            \n",
    "            # Calculate sentiment score (-1 to 1)\n",
    "            # Negative score is -1 * negative_probability\n",
    "            # Positive score is 1 * positive_probability\n",
    "            # Neutral score is 0 * neutral_probability\n",
    "            sentiment_score = score[2] - score[0]  # positive_prob - negative_prob\n",
    "            \n",
    "            sentiment_labels.append(label)\n",
    "            sentiment_scores.append(round(float(sentiment_score), 3))\n",
    "    \n",
    "    return sentiment_labels, sentiment_scores\n",
    "\n",
    "def main():\n",
    "    # Read the input CSV file\n",
    "    input_file = \"risk_contexts.csv\"  # Change this to your input file name\n",
    "    print(f\"Reading input file: {input_file}\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Print column names to verify the text column name\n",
    "    print(\"Columns in the DataFrame:\", df.columns)\n",
    "    \n",
    "    # Perform sentiment analysis\n",
    "    print(\"Performing sentiment analysis...\")\n",
    "    sentiment_labels, sentiment_scores = perform_sentiment_analysis(df, \"context\")  # Change \"context\" to your text column name\n",
    "    \n",
    "    # Add results to DataFrame\n",
    "    df[\"sentiment\"] = sentiment_labels\n",
    "    df[\"sentiment_score\"] = sentiment_scores\n",
    "    \n",
    "    # Save results to new CSV file\n",
    "    output_file = \"risk_contexts_with_sentiment.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nResults saved to {output_file}\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSentiment Distribution:\")\n",
    "    print(pd.Series(sentiment_labels).value_counts())\n",
    "    print(\"\\nSentiment Score Statistics:\")\n",
    "    print(pd.Series(sentiment_scores).describe())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sand box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.15.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /Users/diliyayalikun/Documents/quant/.conda/lib/python3.11/site-packages (from scipy) (2.2.2)\n",
      "Downloading scipy-1.15.1-cp311-cp311-macosx_14_0_arm64.whl (24.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.15.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Model \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring and sentiment\n",
    "text = \"Trump is putting 25% tariff on Mexican and Canadian goods\"\n",
    "# text = preprocess(text) # This is the function that needed to implement the extraction of risk words interval\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) neutral 0.6107\n",
      "2) negative 0.3366\n",
      "3) positive 0.0527\n"
     ]
    }
   ],
   "source": [
    "# Labels and scores\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_twitter(text, model_path):\n",
    "    \"\"\"\n",
    "    Analyze sentiment of a given text using a pre-trained model from Hugging Face.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text to analyze.\n",
    "    - model_path (str): The path to the pre-trained model.\n",
    "\n",
    "    Returns:\n",
    "    - label (str): The sentiment label of the text.\n",
    "    - scores (dict): The sentiment scores for each class.\n",
    "    \"\"\"\n",
    "    # Load the model and tokenizer\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Perform the forward pass\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Get the predicted class label\n",
    "    predicted_class_idx = outputs.logits.argmax().item()\n",
    "    label = model.config.id2label[predicted_class_idx]\n",
    "\n",
    "    #\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file reading\n",
    "def analyze_csv_sentiments(input_csv, output_csv):\n",
    "    # Load the input CSV file\n",
    "    df=pd.read_csv(input_csv)\n",
    "    # Analyze sentiment for each row using our model aand add result to new column\n",
    "    df[f'twitter-roberta-base-sentiment-latest_sentiment'] = df['text'].apply(lambda text: analyze_sentiment_twitter(text, \"cardiffnlp/twitter-roberta-base-sentiment\"))\n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "input_csv = \"test_file.csv\"  # Path to your input CSV file\n",
    "output_csv = \"output_with_sentiments.csv\"  # Path to save the output CSV file with sentiments\n",
    "result_df = analyze_csv_sentiments(input_csv, output_csv)\n",
    "print(result_df.head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing sentiment analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'context'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/quant/.conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'context'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 83\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39mSeries(sentiment_scores)\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[42], line 65\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Perform sentiment analysis\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerforming sentiment analysis...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m sentiment_labels, sentiment_scores \u001b[38;5;241m=\u001b[39m \u001b[43mperform_sentiment_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Change \"context\" to your text column name\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Add results to DataFrame\u001b[39;00m\n\u001b[1;32m     68\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sentiment_labels\n",
      "Cell \u001b[0;32mIn[42], line 25\u001b[0m, in \u001b[0;36mperform_sentiment_analysis\u001b[0;34m(df, text_column)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Process texts in batches\u001b[39;00m\n\u001b[1;32m     24\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m---> 25\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext_column\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts), batch_size)):\n\u001b[1;32m     28\u001b[0m     batch_texts \u001b[38;5;241m=\u001b[39m texts[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n",
      "File \u001b[0;32m~/Documents/quant/.conda/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/quant/.conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'context'"
     ]
    }
   ],
   "source": [
    "# Final function \n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "\n",
    "def perform_sentiment_analysis(df, text_column):\n",
    "    \"\"\"\n",
    "    Perform sentiment analysis on the given DataFrame using twitter-roberta-base-sentiment-latest\n",
    "    \"\"\"\n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Initialize lists to store results\n",
    "    sentiment_labels = []\n",
    "    sentiment_scores = []\n",
    "    \n",
    "    # Process texts in batches\n",
    "    batch_size = 32\n",
    "    texts = df[text_column].tolist()\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        \n",
    "        # Tokenize texts\n",
    "        encoded = tokenizer(batch_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "        \n",
    "        # Get model predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded)\n",
    "            scores = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "            scores = scores.cpu().numpy()\n",
    "        \n",
    "        # Process each prediction in the batch\n",
    "        for score in scores:\n",
    "            # Get label (0: negative, 1: neutral, 2: positive)\n",
    "            label_id = score.argmax()\n",
    "            label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "            label = label_map[label_id]\n",
    "            \n",
    "            # Calculate sentiment score (-1 to 1)\n",
    "            # Negative score is -1 * negative_probability\n",
    "            # Positive score is 1 * positive_probability\n",
    "            # Neutral score is 0 * neutral_probability\n",
    "            sentiment_score = score[2] - score[0]  # positive_prob - negative_prob\n",
    "            \n",
    "            sentiment_labels.append(label)\n",
    "            sentiment_scores.append(round(float(sentiment_score), 3))\n",
    "    \n",
    "    return sentiment_labels, sentiment_scores\n",
    "\n",
    "def main():\n",
    "    # Read the input CSV file\n",
    "    input_file = \"risk_contexts.csv\"  # Change this to your input file name\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Perform sentiment analysis\n",
    "    print(\"Performing sentiment analysis...\")\n",
    "    sentiment_labels, sentiment_scores = perform_sentiment_analysis(df, \"context\")  # Change \"context\" to your text column name\n",
    "    \n",
    "    # Add results to DataFrame\n",
    "    df[\"sentiment\"] = sentiment_labels\n",
    "    df[\"sentiment_score\"] = sentiment_scores\n",
    "    \n",
    "    # Save results to new CSV file\n",
    "    output_file = \"risk_contexts_with_sentiment.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nResults saved to {output_file}\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSentiment Distribution:\")\n",
    "    print(pd.Series(sentiment_labels).value_counts())\n",
    "    print(\"\\nSentiment Score Statistics:\")\n",
    "    print(pd.Series(sentiment_scores).describe())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ryder System Inc', 'R', '02-02-2016', 'MIAMI']\n"
     ]
    }
   ],
   "source": [
    "from functions import extract_exposure2\n",
    "\n",
    "print(extract_company_info(\"/Users/efang/Desktop/coding/research/src/data/earnings_calls/ex1.xml\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
