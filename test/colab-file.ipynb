{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c3c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!rm -rf research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/cwruquants/research.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae92c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/research/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5058d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60025a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install nltk textstat pysentiment2 datasets accelerate ipywidgets word-forms\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852769c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd() # current working directory is /content/research\n",
    "sys.path.insert(0, str(project_root))\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "from research.src.analysis.analyst_module import Analyst\n",
    "from research.src.document.abstract_classes.setup_module import SentimentSetup\n",
    "import toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup configuration for sentiment analysis\n",
    "setup = SentimentSetup(\n",
    "    sheet_name_positive='ML_positive_unigram',\n",
    "    sheet_name_negative='ML_negative_unigram',\n",
    "    ml_wordlist_path=str(project_root / \"data\" / \"word_sets\" / \"Garcia_MLWords.xlsx\"),\n",
    "    device=0,\n",
    "    batch_size=\"auto\",\n",
    "    hf_model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    ")\n",
    "\n",
    "# Create analyst (no keyword_path needed for sentiment-only)\n",
    "analyst = Analyst(setups=[setup])\n",
    "\n",
    "keyword_path = \"/content/research/data/word_sets/risk_paper.csv\"\n",
    "\n",
    "result = analyst.process_directory(\n",
    "    input_dir=\"/content/drive/MyDrive/QUANTS/RESEARCH/EARNINGS_CALLS/2003\",\n",
    "    output_dir=\"/content/drive/MyDrive/QUANTS/RESEARCH/RESULTS\",\n",
    "    batch_folder_name=\"2003\",\n",
    "    run_sentiment=True,\n",
    "    matching_method=None,  # Skip matching for now\n",
    ")\n",
    "\n",
    "print(\"\\nMatching completed!\")\n",
    "print(f\"Match ID: {result['match_id']}\")\n",
    "print(f\"Files processed: {result['num_files_processed']}\")\n",
    "print(f\"Exposure summary CSV: {result['exposure_summary_csv']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
