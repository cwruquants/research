{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\arete\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.analysis.analyst_module import Analyst\n",
    "from src.document.abstract_classes.setup_module import SentimentSetup\n",
    "import toml\n",
    "\n",
    "# Force reload the module to pick up any code changes\n",
    "import src.analysis.analyst_module\n",
    "importlib.reload(src.analysis.analyst_module)\n",
    "from src.analysis.analyst_module import Analyst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Sentiment-Only Batch Processing\n",
    "\n",
    "Run sentiment analysis on all earnings calls without keyword matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 1: Sentiment-only batch processing\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Setup configuration for sentiment analysis\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m setup = \u001b[43mSetup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43msheet_name_positive\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mML_positive_unigram\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43msheet_name_negative\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mML_negative_unigram\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mproject_root\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mword_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGarcia_MLWords.xlsx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhf_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcardiffnlp/twitter-roberta-base-sentiment-latest\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Create analyst (no keyword_path needed for sentiment-only)\u001b[39;00m\n\u001b[32m     15\u001b[39m analyst = Analyst(setup=setup)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arete\\Cursor\\research\\src\\document\\abstract_classes\\setup_module.py:29\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, sheet_name_positive, sheet_name_negative, file_path, hf_model, device, batch_size, max_length)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSetup\u001b[39;00m:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     25\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     26\u001b[39m         sheet_name_positive: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mML_positive_unigram\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m         sheet_name_negative: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mML_negative_unigram\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m         file_path: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mdata/word_sets/Garcia_MLWords.xlsx\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m         hf_model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mcardiffnlp/twitter-roberta-base-sentiment-latest\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     30\u001b[39m         device: \u001b[38;5;28mint\u001b[39m = -\u001b[32m1\u001b[39m,\n\u001b[32m     31\u001b[39m         batch_size: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m] = \u001b[32m32\u001b[39m,\n\u001b[32m     32\u001b[39m         max_length: \u001b[38;5;28mint\u001b[39m = \u001b[32m512\u001b[39m,\n\u001b[32m     33\u001b[39m     ):\n\u001b[32m     34\u001b[39m         \u001b[38;5;28mself\u001b[39m.transformer = pipeline(\n\u001b[32m     35\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msentiment-analysis\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     36\u001b[39m             model=hf_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m             max_length=max_length,\n\u001b[32m     40\u001b[39m         )\n\u001b[32m     41\u001b[39m         \u001b[38;5;28mself\u001b[39m.lm = ps.LM()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arete\\Cursor\\research\\.venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:1030\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1029\u001b[39m     model_classes = {\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m     framework, model = \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1040\u001b[39m model_config = model.config\n\u001b[32m   1041\u001b[39m hub_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = model.config._commit_hash\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arete\\Cursor\\research\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:292\u001b[39m, in \u001b[36minfer_framework_load_model\u001b[39m\u001b[34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m     logger.warning(\n\u001b[32m    287\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    288\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTrying to load the model with Tensorflow.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    289\u001b[39m     )\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     model = \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33meval\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    294\u001b[39m         model = model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arete\\Cursor\\research\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:563\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    560\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mquantization_config\u001b[39m\u001b[33m\"\u001b[39m] = kwargs_orig[\u001b[33m\"\u001b[39m\u001b[33mquantization_config\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    562\u001b[39m has_remote_code = \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[33m\"\u001b[39m\u001b[33mauto_map\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config.auto_map\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m has_local_code = \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model_mapping\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m upstream_repo = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arete\\Cursor\\research\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:821\u001b[39m, in \u001b[36m_LazyAutoMapping.keys\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    819\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mkeys\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtype\u001b[39m[PretrainedConfig]]:\n\u001b[32m    820\u001b[39m     mapping_keys = [\n\u001b[32m--> \u001b[39m\u001b[32m821\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_attr_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m key, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._config_mapping.items()\n\u001b[32m    823\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._model_mapping.keys()\n\u001b[32m    824\u001b[39m     ]\n\u001b[32m    825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping_keys + \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m._extra_content.keys())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arete\\Cursor\\research\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:816\u001b[39m, in \u001b[36m_LazyAutoMapping._load_attr_from_module\u001b[39m\u001b[34m(self, model_type, attr)\u001b[39m\n\u001b[32m    814\u001b[39m module_name = model_type_to_module_name(model_type)\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m     \u001b[38;5;28mself\u001b[39m._modules[module_name] = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodule_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtransformers.models\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m getattribute_from_module(\u001b[38;5;28mself\u001b[39m._modules[module_name], attr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1026\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arete\\Cursor\\research\\.venv\\Lib\\site-packages\\transformers\\models\\openai\\__init__.py:30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m     29\u001b[39m _file = \u001b[38;5;28mglobals\u001b[39m()[\u001b[33m\"\u001b[39m\u001b[33m__file__\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m sys.modules[\u001b[34m__name__\u001b[39m] = _LazyModule(\u001b[34m__name__\u001b[39m, _file, \u001b[43mdefine_import_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_file\u001b[49m\u001b[43m)\u001b[49m, module_spec=__spec__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arete\\Cursor\\research\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2703\u001b[39m, in \u001b[36mdefine_import_structure\u001b[39m\u001b[34m(module_path, prefix)\u001b[39m\n\u001b[32m   2679\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[32m   2680\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefine_import_structure\u001b[39m(module_path: \u001b[38;5;28mstr\u001b[39m, prefix: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> IMPORT_STRUCTURE_T:\n\u001b[32m   2681\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2682\u001b[39m \u001b[33;03m    This method takes a module_path as input and creates an import structure digestible by a _LazyModule.\u001b[39;00m\n\u001b[32m   2683\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2701\u001b[39m \u001b[33;03m    If `prefix` is not None, it will add that prefix to all keys in the returned dict.\u001b[39;00m\n\u001b[32m   2702\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2703\u001b[39m     import_structure = \u001b[43mcreate_import_structure_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2704\u001b[39m     spread_dict = spread_import_structure(import_structure)\n\u001b[32m   2706\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arete\\Cursor\\research\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2408\u001b[39m, in \u001b[36mcreate_import_structure_from_path\u001b[39m\u001b[34m(module_path)\u001b[39m\n\u001b[32m   2353\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2354\u001b[39m \u001b[33;03mThis method takes the path to a file/a folder and returns the import structure.\u001b[39;00m\n\u001b[32m   2355\u001b[39m \u001b[33;03mIf a file is given, it will return the import structure of the parent folder.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2404\u001b[39m \u001b[33;03m}\u001b[39;00m\n\u001b[32m   2405\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2406\u001b[39m import_structure = {}\n\u001b[32m-> \u001b[39m\u001b[32m2408\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43misfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   2409\u001b[39m     module_path = os.path.dirname(module_path)\n\u001b[32m   2411\u001b[39m directory = module_path\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TEST 1: Sentiment-only batch processing\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Setup configuration for sentiment analysis\n",
    "sentiment_setup = SentimentSetup(\n",
    "    sheet_name_positive='ML_positive_unigram',\n",
    "    sheet_name_negative='ML_negative_unigram',\n",
    "    file_path=str(project_root / \"data\" / \"word_sets\" / \"Garcia_MLWords.xlsx\"),\n",
    "    hf_model='cardiffnlp/twitter-roberta-base-sentiment-latest',\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# Create analyst (no keyword_path needed for sentiment-only)\n",
    "analyst = Analyst(setup=sentiment_setup)\n",
    "\n",
    "# Run batch processing without keyword matching\n",
    "result = analyst.process_directory(\n",
    "    input_dir=str(project_root / \"data\" / \"earnings_calls\" / \"2016\"),\n",
    "    output_dir=str(project_root / \"results\"),\n",
    "    run_matching=False,  # Sentiment analysis only (default behavior)\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Batch directory created: {result['batch_directory']}\")\n",
    "print(f\"✓ Batch summary CSV: {result['csv_path']}\")\n",
    "print(f\"✓ Files processed: {result['num_files_processed']}\")\n",
    "\n",
    "# Save batch directory for next test, or you can just set the variable of batch directory yourself\n",
    "batch_dir = result['batch_directory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Matching on Existing Batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST 2: Direct matching on existing batch\n",
      "================================================================================\n",
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9771af4f77439abe17ef4750b945a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Matching keywords:   0%|          | 0/26019 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Matching completed!\n",
      "✓ Match ID: political_words_20251111_194350\n",
      "✓ Files processed: 0\n",
      "✓ Exposure summary CSV: c:\\Users\\arete\\Cursor\\research\\results\\batch_20251030_031511-20251030T201729Z-1-001\\batch_20251030_031511\\exposure_summary_political_words_20251111_194350.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TEST 2: Direct matching on existing batch\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Specify the existing batch directory (adjust path as needed)\n",
    "# The batch directory should contain subdirectories, each representing an earnings call\n",
    "existing_batch_dir = str(project_root / \"results\" / \"batch_20251030_031511-20251030T201729Z-1-001\" / \"batch_20251030_031511\")\n",
    "\n",
    "# Or use a variable if you ran Test 1:\n",
    "# existing_batch_dir = batch_dir\n",
    "\n",
    "# Create analyst (no setup needed for matching-only)\n",
    "analyst = Analyst()\n",
    "\n",
    "# Specify keyword file\n",
    "keyword_path = str(project_root / \"data\" / \"paper_word_sets\" / \"political_words.csv\")\n",
    "\n",
    "# Run direct keyword matching only\n",
    "result = analyst.process_existing_batch(\n",
    "    batch_dir=existing_batch_dir,\n",
    "    keyword_path=keyword_path,\n",
    "    similarity=\"direct\",  # Use \"direct\" for exact matching only\n",
    "    transcript_roots=[project_root / \"data\" / \"earnings_calls\" / \"2016\"],\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Matching completed!\")\n",
    "print(f\"✓ Match ID: {result['match_id']}\")\n",
    "print(f\"✓ Files processed: {result['num_files_processed']}\")\n",
    "print(f\"✓ Exposure summary CSV: {result['exposure_summary_csv']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
